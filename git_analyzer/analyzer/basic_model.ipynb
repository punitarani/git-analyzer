{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Basic Git Commit Analyzer Model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [],
   "source": [
    "# Paths\n",
    "data_dir = Path(\"__file__\").absolute().parent.parent.parent.joinpath(\"data\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "outputs": [],
   "source": [
    "# Constants\n",
    "repo_name = \"tensorflow\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Repository Statistics"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repo path: C:\\Users\\punit\\OneDrive\\Documents\\Projects\\git-analyzer\\data\\tensorflow\n",
      "Files size: 48019.57 KB\n",
      "# Indexed Files:  2500\n",
      "Index(['sha', 'node_id', 'commit', 'url', 'html_url', 'comments_url', 'author',\n",
      "       'committer', 'parents'],\n",
      "      dtype='object')\n",
      "\n",
      "sha                      2a7ca476f44c58814d182c23d7f41a813468188e\n",
      "node_id         C_kwDOArmXAtoAKDJhN2NhNDc2ZjQ0YzU4ODE0ZDE4MmMy...\n",
      "commit          {'author': {'name': 'Jean-Baptiste Lespiau', '...\n",
      "url             https://api.github.com/repos/tensorflow/tensor...\n",
      "html_url        https://github.com/tensorflow/tensorflow/commi...\n",
      "comments_url    https://api.github.com/repos/tensorflow/tensor...\n",
      "author          {'login': 'jblespiau', 'id': 534945, 'node_id'...\n",
      "committer       {'login': 'tensorflower-gardener', 'id': 17151...\n",
      "parents         [{'sha': '10fe17255335e16aac9f828764050bd2c087...\n",
      "Name: 0, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Repo Path\n",
    "repo_path = data_dir.joinpath(repo_name)\n",
    "if not repo_path.exists():\n",
    "    raise ValueError(f\"Repo path does not exist: {repo_path}\")\n",
    "\n",
    "# Repo stats\n",
    "print(f\"Repo path: {repo_path}\")\n",
    "files_size = sum(f.stat().st_size for f in repo_path.glob('**/*.parquet') if f.is_file())\n",
    "print(f\"Files size: {files_size / 1024:.2f} KB\")\n",
    "\n",
    "# Load index\n",
    "index_df = pd.read_csv(repo_path.joinpath(\"index.csv\"), encoding=\"utf-8-sig\")\n",
    "\n",
    "# Print index stats\n",
    "print(f\"# Indexed Files: \", index_df.shape[0])\n",
    "print(index_df.columns)\n",
    "\n",
    "# Print index\n",
    "print()\n",
    "print(index_df.iloc[0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Helper Functions"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "outputs": [],
   "source": [
    "def get_file(sha: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Loads a file from the repo.\n",
    "    :param sha: SHA of the commit/file.\n",
    "    :return: Dataframe with the file.\n",
    "    \"\"\"\n",
    "    file_name = f\"{sha}.parquet\"\n",
    "    df = pd.read_parquet(repo_path.joinpath(file_name))\n",
    "    df[\"file\"] = df[\"filename\"].apply(lambda x: x.split(\"/\")[-1])\n",
    "    df.set_index(\"file\", inplace=True)\n",
    "    return df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "outputs": [],
   "source": [
    "def parse_patch(\n",
    "        patch: str,\n",
    "        file_extension: str = None,\n",
    ") -> list[list[list[str]]]:\n",
    "    \"\"\"\n",
    "    Parses a patch and returns a list of lines.\n",
    "    :param patch: Patch string to parse.\n",
    "    :param file_extension: File extension.\n",
    "    :return: List of lines.\n",
    "    \"\"\"\n",
    "\n",
    "    # Get language\n",
    "    if file_extension in [\"c\", \"cpp\", \"h\", \"hpp\"]:\n",
    "        language = \"c\"\n",
    "    elif file_extension in [\"py\"]:\n",
    "        language = \"py\"\n",
    "    else:\n",
    "        language = \"c\"\n",
    "\n",
    "    # Comments dict\n",
    "    comments = {\n",
    "        \"c\": [\"//\"],\n",
    "        \"py\": [\"#\"],\n",
    "    }\n",
    "\n",
    "    # Create output list\n",
    "    parsed = []\n",
    "\n",
    "    # Split patch into lines\n",
    "    lines = patch.split(\"\\n\")\n",
    "\n",
    "    # Create additions and deletions\n",
    "    additions = []\n",
    "    deletions = []\n",
    "\n",
    "    # Iterate through each line and parse it\n",
    "    for line in lines:\n",
    "        # Get only modified lines\n",
    "        if line.startswith(\"+\") or line.startswith(\"-\"):\n",
    "            # ADDITIONS\n",
    "            if line.startswith(\"+\"):\n",
    "\n",
    "                # Remove leading and trailing whitespace\n",
    "                line = line[1:].strip()\n",
    "                # Don't add empty lines\n",
    "                if line != \"\":\n",
    "                    # Check for single line comments\n",
    "                    if not line.startswith(comments[language][0]):\n",
    "                        # Add line to additions\n",
    "                        additions.append(line)\n",
    "\n",
    "            # DELETIONS\n",
    "            else:\n",
    "                # Create next set\n",
    "                if len(additions) > 0:\n",
    "                    # Add to output\n",
    "                    parsed.append([deletions, additions])\n",
    "\n",
    "                    # Create new set\n",
    "                    additions = []\n",
    "                    deletions = []\n",
    "\n",
    "                # Remove leading and trailing whitespace\n",
    "                line = line[1:].strip()\n",
    "\n",
    "                # Don't add empty lines\n",
    "                if line.strip() != \"\":\n",
    "                    # Check for single line comments\n",
    "                    if not line.startswith(comments[language][0]):\n",
    "                        # Add line to deletions\n",
    "                        deletions.append(line)\n",
    "\n",
    "    # Add last set if not empty\n",
    "    if len(additions) > 0 or len(deletions) > 0:\n",
    "        parsed.append([deletions, additions])\n",
    "\n",
    "    return parsed"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Load Files"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random index: 1143\n"
     ]
    }
   ],
   "source": [
    "# Pick a random number\n",
    "random_index = int(len(index_df) * np.random.random())\n",
    "print(f\"Random index: {random_index}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File (sha): b85eb7f22bde6822b686d54330d77cd419e23aa0\n",
      "# Changed:  5\n",
      "                                         additions  deletions  changes\n",
      "file                                                                  \n",
      "quantized_function_library.mlir                  3          1        4\n",
      "replace_cast_hacks_with_tf_xla_ops.cc           79         52      131\n",
      "replace_cast_hacks_with_tf_xla_ops.td           72          3       75\n",
      "utils.td                                        13          0       13\n",
      "replace_cast_hacks_with_tf_xla_ops.mlir         84          0       84\n"
     ]
    }
   ],
   "source": [
    "# Load the random file\n",
    "file_sha = index_df.iloc[random_index][\"sha\"]\n",
    "file_df = get_file(file_sha)\n",
    "print(f\"File (sha): {file_sha}\")\n",
    "print(f\"# Changed: \", file_df.shape[0])\n",
    "print(file_df[[\"additions\", \"deletions\", \"changes\"]])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Raw Patch"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File name: quantized_function_library.mlir\n",
      "File path: tensorflow/compiler/mlir/quantization/tensorflow/passes/quantized_function_library.mlir\n",
      "Patch: \n",
      "@@ -167,9 +167,11 @@ module {\n",
      " \n",
      "     %2 = \"tf.Cast\"(%filter) {Truncate = false} : (tensor<*xi8>) -> tensor<*xi32>\n",
      "     %3 = \"tf.Sub\"(%2, %filter_zp) : (tensor<*xi32>, tensor<*xi32>) -> tensor<*xi32>\n",
      "+    // Use identity op to avoid the filter being folded.\n",
      "+    %identity = \"tf.Identity\"(%3) : (tensor<*xi32>) -> tensor<*xi32>\n",
      " \n",
      "     %cast_1_f32 = \"tf.Cast\"(%1) {Truncate = false} : (tensor<*xi32>) -> tensor<*xf32>\n",
      "-    %cast_3_f32 = \"tf.Cast\"(%3) {Truncate = false} : (tensor<*xi32>) -> tensor<*xf32>\n",
      "+    %cast_3_f32 = \"tf.Cast\"(%identity) {Truncate = false} : (tensor<*xi32>) -> tensor<*xf32>\n",
      " \n",
      "     // TODO(b/215633216): Optimize this function with the XLA convolution op.\n",
      "     %5 = \"tf.DepthwiseConv2dNative\"(%cast_1_f32, %cast_3_f32) {\n",
      "\n",
      " ================================================================================ \n",
      "\n",
      "File name: replace_cast_hacks_with_tf_xla_ops.cc\n",
      "File path: tensorflow/compiler/mlir/quantization/tensorflow/passes/replace_cast_hacks_with_tf_xla_ops.cc\n",
      "Patch: \n",
      "@@ -56,13 +56,13 @@ void PrepareXlaConvParams(OpBuilder &builder, Location loc, ArrayAttr strides,\n",
      "                           ArrayAttr dilations, int feature_group_cnt,\n",
      "                           Value &window_strides, Value &lhs_dilation,\n",
      "                           Value &rhs_dilation, Value &feature_group_count) {\n",
      "-  const int stride_h = strides[1].cast<mlir::IntegerAttr>().getInt();\n",
      "-  const int stride_w = strides[2].cast<mlir::IntegerAttr>().getInt();\n",
      "+  const int stride_h = strides[1].cast<IntegerAttr>().getInt();\n",
      "+  const int stride_w = strides[2].cast<IntegerAttr>().getInt();\n",
      "   window_strides =\n",
      "       Create1DConstValue<int32_t>(builder, loc, {stride_h, stride_w});\n",
      " \n",
      "-  const int dilation_h = dilations[1].cast<mlir::IntegerAttr>().getInt();\n",
      "-  const int dilation_w = dilations[2].cast<mlir::IntegerAttr>().getInt();\n",
      "+  const int dilation_h = dilations[1].cast<IntegerAttr>().getInt();\n",
      "+  const int dilation_w = dilations[2].cast<IntegerAttr>().getInt();\n",
      "   lhs_dilation = Create1DConstValue<int32_t>(builder, loc, {1, 1});\n",
      "   rhs_dilation =\n",
      "       Create1DConstValue<int32_t>(builder, loc, {dilation_h, dilation_w});\n",
      "@@ -82,23 +82,22 @@ Value CalculatePaddingAndPadIfNeeded(\n",
      "   int padding_h_before, padding_h_after, padding_w_before, padding_w_after;\n",
      "   if (conv_padding.strref().equals(\"EXPLICIT\")) {\n",
      "     if (explicit_paddings.size() != 8) {\n",
      "-      mlir::emitError(loc,\n",
      "-                      \"explicit_paddings are expected to be 8-element arrays\");\n",
      "+      emitError(loc, \"explicit_paddings are expected to be 8-element arrays\");\n",
      "       return {};\n",
      "     }\n",
      "-    padding_h_before = explicit_paddings[2].cast<mlir::IntegerAttr>().getInt();\n",
      "-    padding_h_after = explicit_paddings[3].cast<mlir::IntegerAttr>().getInt();\n",
      "-    padding_w_before = explicit_paddings[4].cast<mlir::IntegerAttr>().getInt();\n",
      "-    padding_w_after = explicit_paddings[5].cast<mlir::IntegerAttr>().getInt();\n",
      "+    padding_h_before = explicit_paddings[2].cast<IntegerAttr>().getInt();\n",
      "+    padding_h_after = explicit_paddings[3].cast<IntegerAttr>().getInt();\n",
      "+    padding_w_before = explicit_paddings[4].cast<IntegerAttr>().getInt();\n",
      "+    padding_w_after = explicit_paddings[5].cast<IntegerAttr>().getInt();\n",
      "   } else {\n",
      "     TfLitePadding tflite_padding = conv_padding.strref().equals(\"VALID\")\n",
      "                                        ? kTfLitePaddingValid\n",
      "                                        : kTfLitePaddingSame;\n",
      "     int output_height, output_width;\n",
      "-    const int stride_h = strides[1].cast<mlir::IntegerAttr>().getInt();\n",
      "-    const int stride_w = strides[2].cast<mlir::IntegerAttr>().getInt();\n",
      "-    const int dilation_h = dilations[1].cast<mlir::IntegerAttr>().getInt();\n",
      "-    const int dilation_w = dilations[2].cast<mlir::IntegerAttr>().getInt();\n",
      "+    const int stride_h = strides[1].cast<IntegerAttr>().getInt();\n",
      "+    const int stride_w = strides[2].cast<IntegerAttr>().getInt();\n",
      "+    const int dilation_h = dilations[1].cast<IntegerAttr>().getInt();\n",
      "+    const int dilation_w = dilations[2].cast<IntegerAttr>().getInt();\n",
      "     TfLitePaddingValues padding_values = tflite::ComputePaddingHeightWidth(\n",
      "         stride_h, stride_w, dilation_h, dilation_w,\n",
      "         /*in_height=*/input_shape.getDimSize(1),\n",
      "@@ -153,30 +152,39 @@ Value CalculateZeroPointOffset(\n",
      " }\n",
      " \n",
      " // Helper function to create a XlaConvV2Op for Conv2DOp and DepthwiseConv2DOp.\n",
      "-Value CreateXLAConvOp(\n",
      "-    OpBuilder &builder, Location loc, Value input, Value filter, Value input_zp,\n",
      "-    Value conv_output, ArrayAttr strides, ArrayAttr dilations,\n",
      "-    StringAttr conv_padding, ArrayAttr explicit_paddings, int feature_group_cnt,\n",
      "-    const SmallVector<int64_t> &filter_non_output_indices,\n",
      "-    const xla::ConvolutionDimensionNumbers &dimension_numbers) {\n",
      "+Value CreateXLAConvOp(OpBuilder &builder, Location loc, Value input,\n",
      "+                      Value filter, Value input_zp, Value conv_output,\n",
      "+                      ArrayAttr strides, ArrayAttr dilations,\n",
      "+                      StringAttr conv_padding, ArrayAttr explicit_paddings,\n",
      "+                      int feature_group_cnt) {\n",
      "   int32_t input_zp_value;\n",
      "   if (!GetSplatValue(input_zp, input_zp_value)) {\n",
      "-    mlir::emitError(\n",
      "-        loc, \"zero point is expected to be a constant with a single value\");\n",
      "+    emitError(loc,\n",
      "+              \"zero point is expected to be a constant with a single value\");\n",
      "     return {};\n",
      "   }\n",
      "   if (strides.size() != 4 || dilations.size() != 4) {\n",
      "-    mlir::emitError(\n",
      "-        loc, \"strides and dilations are expected to be 4-element arrays\");\n",
      "+    emitError(loc, \"strides and dilations are expected to be 4-element arrays\");\n",
      "     return {};\n",
      "   }\n",
      "-  ShapedType input_shape = input.getType().template cast<ShapedType>();\n",
      "   ShapedType filter_shape = filter.getType().template cast<ShapedType>();\n",
      "-  if (!input_shape.hasRank() || input_shape.getRank() != 4 ||\n",
      "-      !filter_shape.hasRank() || filter_shape.getRank() != 4) {\n",
      "-    mlir::emitError(loc, \"input and filter are expected to be 4D tensors\");\n",
      "-    return {};\n",
      "-  }\n",
      "+  SmallVector<int64_t> filter_non_output_indices = {0, 1, 2};\n",
      "+  xla::ConvolutionDimensionNumbers dnums;\n",
      "+  // Input: [N, H, W, C].\n",
      "+  dnums.set_input_batch_dimension(0);\n",
      "+  dnums.set_input_feature_dimension(3);\n",
      "+  dnums.add_input_spatial_dimensions(1);\n",
      "+  dnums.add_input_spatial_dimensions(2);\n",
      "+  // Kernel: [K, K, I, O].\n",
      "+  dnums.set_kernel_input_feature_dimension(2);\n",
      "+  dnums.set_kernel_output_feature_dimension(3);\n",
      "+  dnums.add_kernel_spatial_dimensions(0);\n",
      "+  dnums.add_kernel_spatial_dimensions(1);\n",
      "+  // Output: [N, H, W, C].\n",
      "+  dnums.set_output_batch_dimension(0);\n",
      "+  dnums.set_output_feature_dimension(3);\n",
      "+  dnums.add_output_spatial_dimensions(1);\n",
      "+  dnums.add_output_spatial_dimensions(2);\n",
      " \n",
      "   Value padding, window_strides, lhs_dilation, rhs_dilation,\n",
      "       feature_group_count;\n",
      "@@ -189,17 +197,17 @@ Value CreateXLAConvOp(\n",
      "   input = CalculatePaddingAndPadIfNeeded(\n",
      "       builder, loc, input, filter, input_zp_value, strides, dilations,\n",
      "       conv_padding, explicit_paddings, padding);\n",
      "-  auto filter_type = filter.getType().dyn_cast<TensorType>();\n",
      "+  TensorType filter_type = filter.getType().dyn_cast<TensorType>();\n",
      "   Value filter_i8 = builder.create<TF::CastOp>(\n",
      "       loc, filter_type.clone(builder.getIntegerType(8)), filter);\n",
      "   Value xla_conv_output =\n",
      "       builder\n",
      "           .create<TF::XlaConvV2Op>(\n",
      "-              loc, /*output=*/conv_output.getType(),\n",
      "+              loc, /*output_type=*/conv_output.getType(),\n",
      "               /*lhs=*/input,\n",
      "               /*rhs=*/filter_i8, window_strides, padding, lhs_dilation,\n",
      "               rhs_dilation, feature_group_count,\n",
      "-              builder.getStringAttr(dimension_numbers.SerializeAsString()),\n",
      "+              builder.getStringAttr(dnums.SerializeAsString()),\n",
      "               /*precision_config=*/builder.getStringAttr(\"\"))\n",
      "           .output();\n",
      "   if (input_zp_value == 0) return xla_conv_output;\n",
      "@@ -218,27 +226,46 @@ Value CreateXLAConvOpFromTFConv2DOp(OpBuilder &builder, Location loc,\n",
      "                                     ArrayAttr dilations,\n",
      "                                     StringAttr conv_padding,\n",
      "                                     ArrayAttr explicit_paddings) {\n",
      "-  const int feature_group_cnt = 1;\n",
      "-  SmallVector<int64_t> filter_non_output_indices = {0, 1, 2};\n",
      "-  xla::ConvolutionDimensionNumbers dnums;\n",
      "-  // Input: [N, H, W, C].\n",
      "-  dnums.set_input_batch_dimension(0);\n",
      "-  dnums.set_input_feature_dimension(3);\n",
      "-  dnums.add_input_spatial_dimensions(1);\n",
      "-  dnums.add_input_spatial_dimensions(2);\n",
      "-  // Kernel: [K, K, I, O].\n",
      "-  dnums.set_kernel_input_feature_dimension(2);\n",
      "-  dnums.set_kernel_output_feature_dimension(3);\n",
      "-  dnums.add_kernel_spatial_dimensions(0);\n",
      "-  dnums.add_kernel_spatial_dimensions(1);\n",
      "-  // Output: [N, H, W, C].\n",
      "-  dnums.set_output_batch_dimension(0);\n",
      "-  dnums.set_output_feature_dimension(3);\n",
      "-  dnums.add_output_spatial_dimensions(1);\n",
      "-  dnums.add_output_spatial_dimensions(2);\n",
      "+  ShapedType input_shape = input.getType().template cast<ShapedType>();\n",
      "+  ShapedType filter_shape = filter.getType().template cast<ShapedType>();\n",
      "+  if (!input_shape.hasRank() || input_shape.getRank() != 4 ||\n",
      "+      !filter_shape.hasRank() || filter_shape.getRank() != 4) {\n",
      "+    emitError(loc, \"input and filter are expected to be 4D tensors\");\n",
      "+    return {};\n",
      "+  }\n",
      "+\n",
      "+  const int feature_group_cnt =\n",
      "+      input_shape.getDimSize(3) / filter_shape.getDimSize(2);\n",
      "   return CreateXLAConvOp(builder, loc, input, filter, input_zp, conv_output,\n",
      "                          strides, dilations, conv_padding, explicit_paddings,\n",
      "-                         feature_group_cnt, filter_non_output_indices, dnums);\n",
      "+                         feature_group_cnt);\n",
      "+}\n",
      "+\n",
      "+// Creates a XlaConvV2Op from TF DepthConv2DOp and returns its output.\n",
      "+Value CreateXLAConvOpFromTFDepthwiseConv2DOp(\n",
      "+    OpBuilder &builder, Location loc, Value input, Value filter, Value input_zp,\n",
      "+    Value conv_output, ArrayAttr strides, ArrayAttr dilations,\n",
      "+    StringAttr conv_padding, ArrayAttr explicit_paddings) {\n",
      "+  ShapedType input_shape = input.getType().template cast<ShapedType>();\n",
      "+  ShapedType filter_shape = filter.getType().template cast<ShapedType>();\n",
      "+  if (!input_shape.hasRank() || input_shape.getRank() != 4 ||\n",
      "+      !filter_shape.hasRank() || filter_shape.getRank() != 4) {\n",
      "+    emitError(loc, \"input and filter are expected to be 4D tensors\");\n",
      "+    return {};\n",
      "+  }\n",
      "+  const int feature_group_cnt = input_shape.getDimSize(3);\n",
      "+\n",
      "+  // Reshape the filter to [K, K, 1, I * O].\n",
      "+  llvm::SmallVector<int64_t> new_filter_shape{\n",
      "+      filter_shape.getDimSize(0), filter_shape.getDimSize(1), 1,\n",
      "+      filter_shape.getDimSize(2) * filter_shape.getDimSize(3)};\n",
      "+  Value new_filter = builder.create<TF::ReshapeOp>(\n",
      "+      loc,\n",
      "+      RankedTensorType::get(new_filter_shape, filter_shape.getElementType()),\n",
      "+      filter, Create1DConstValue(builder, loc, new_filter_shape));\n",
      "+  return CreateXLAConvOp(builder, loc, input, new_filter, input_zp, conv_output,\n",
      "+                         strides, dilations, conv_padding, explicit_paddings,\n",
      "+                         feature_group_cnt);\n",
      " }\n",
      " \n",
      " #include \"tensorflow/compiler/mlir/quantization/tensorflow/passes/replace_cast_hacks_with_tf_xla_ops.inc\"\n",
      "\n",
      " ================================================================================ \n",
      "\n",
      "File name: replace_cast_hacks_with_tf_xla_ops.td\n",
      "File path: tensorflow/compiler/mlir/quantization/tensorflow/passes/replace_cast_hacks_with_tf_xla_ops.td\n",
      "Patch: \n",
      "@@ -22,11 +22,17 @@ include \"tensorflow/compiler/mlir/quantization/tensorflow/passes/utils.td\"\n",
      " def CreateXLAConvOpFromTFConv2DOp : NativeCodeCall<\n",
      "   \"CreateXLAConvOpFromTFConv2DOp($_builder, $_loc, $0...)\">;\n",
      " \n",
      "+def CreateXLAConvOpFromTFDepthwiseConv2DOp : NativeCodeCall<\n",
      "+  \"CreateXLAConvOpFromTFDepthwiseConv2DOp($_builder, $_loc, $0...)\">;\n",
      "+\n",
      "+// Converts inlined Conv2D pattern to TF XlaConvV2 op. This pattern doesn't\n",
      "+// support non-constant weights or large weights (where the constant folding\n",
      "+// fails).\n",
      " def ConvertTFConv2DToXLAConvOp : Pat<\n",
      "   (TF_Conv2DOp:$conv\n",
      "-     (TF_SubOp (TF_CastOp $input, $truncate), $input_zp),\n",
      "-     (TF_ConstOp:$filter $filter_value),\n",
      "-     $strides, $use_cudnn, $padding, $explicit_padding,\n",
      "+    (TF_SubOp (TF_CastOp $input, $truncate), $input_zp),\n",
      "+    (TF_ConstOp:$filter $filter_value),\n",
      "+    $strides, $use_cudnn, $padding, $explicit_padding,\n",
      "     IsDataFormatNHWC:$data_format, $dilations),\n",
      "   (CreateXLAConvOpFromTFConv2DOp\n",
      "     $input, $filter, $input_zp, $conv, $strides,\n",
      "@@ -37,3 +43,66 @@ def ConvertTFConv2DToXLAConvOp : Pat<\n",
      "    (HasStaticShapeConstraint $filter),\n",
      "    (HasStaticShapeAtDimsConstraint<\"1, 2, 3\"> $input)],\n",
      "   (addBenefit 10)>;\n",
      "+\n",
      "+// Same as ConvertTFConv2DToXLAConvOp but handles the case where input zero\n",
      "+// point is 0 and the Sub op has been folded.\n",
      "+def ConvertTFConv2DWithNoZeroPointToXLAConvOp : Pat<\n",
      "+  (TF_Conv2DOp:$conv\n",
      "+    (TF_CastOp $input, $truncate),\n",
      "+    (TF_ConstOp:$filter $filter_value),\n",
      "+    $strides, $use_cudnn, $padding, $explicit_padding,\n",
      "+    IsDataFormatNHWC:$data_format, $dilations),\n",
      "+  (CreateXLAConvOpFromTFConv2DOp\n",
      "+    $input, $filter, /*input_zp=*/(CreateScalarIntegerConst<\"int32_t\", \"0\">),\n",
      "+    $conv, $strides, $dilations, $padding, $explicit_padding),\n",
      "+  [(IsInt8ElementType $input),\n",
      "+   (IsInt32ElementType $filter),\n",
      "+   (IsInt32ElementType $conv),\n",
      "+   (HasStaticShapeConstraint $filter),\n",
      "+   (HasStaticShapeAtDimsConstraint<\"1, 2, 3\"> $input)],\n",
      "+  (addBenefit 10)>;\n",
      "+\n",
      "+// Converts inlined DepthwiseConv2D pattern to TF XlaConvV2 op. This pattern\n",
      "+// doesn't support non-constant weights or large weights (where the constant\n",
      "+// folding fails).\n",
      "+def ConvertTFDepthwiseConv2DToXLAConvOp : Pat<\n",
      "+  (TF_CastOp:$conv\n",
      "+    (TF_DepthwiseConv2dNativeOp\n",
      "+      (TF_CastOp:$casted_input\n",
      "+        (TF_SubOp (TF_CastOp $input, $truncate1), $input_zp), $truncate2),\n",
      "+      (TF_CastOp\n",
      "+        (TF_IdentityOp (TF_ConstOp:$filter $filter_value)), $truncate3),\n",
      "+      $strides, $padding, $explicit_padding,\n",
      "+      IsDataFormatNHWC:$data_format, $dilations), $truncate4),\n",
      "+  (CreateXLAConvOpFromTFDepthwiseConv2DOp\n",
      "+    $input, $filter, $input_zp, $conv, $strides,\n",
      "+    $dilations, $padding, $explicit_padding),\n",
      "+  [(IsInt8ElementType $input),\n",
      "+   (IsF32ElementType $casted_input),\n",
      "+   (IsInt32ElementType $filter),\n",
      "+   (IsInt32ElementType $conv),\n",
      "+   (HasStaticShapeConstraint $filter),\n",
      "+   (HasStaticShapeAtDimsConstraint<\"1, 2, 3\"> $input)],\n",
      "+  (addBenefit 10)>;\n",
      "+\n",
      "+// Same as ConvertTFDepthwiseConv2DToXLAConvOp but handles the case where input\n",
      "+// zero point is 0 and the Sub op has been folded.\n",
      "+def ConvertTFDepthwiseConv2DWithNoZeroPointToXLAConvOp : Pat<\n",
      "+  (TF_CastOp:$conv\n",
      "+    (TF_DepthwiseConv2dNativeOp\n",
      "+      (TF_CastOp:$casted_input\n",
      "+        (TF_CastOp $input, $truncate1), $truncate2),\n",
      "+      (TF_CastOp\n",
      "+        (TF_IdentityOp (TF_ConstOp:$filter $filter_value)), $truncate3),\n",
      "+      $strides, $padding, $explicit_padding,\n",
      "+      IsDataFormatNHWC:$data_format, $dilations), $truncate4),\n",
      "+  (CreateXLAConvOpFromTFDepthwiseConv2DOp\n",
      "+    $input, $filter, /*input_zp=*/(CreateScalarIntegerConst<\"int32_t\", \"0\">),\n",
      "+    $conv, $strides, $dilations, $padding, $explicit_padding),\n",
      "+  [(IsInt8ElementType $input),\n",
      "+   (IsF32ElementType $casted_input),\n",
      "+   (IsInt32ElementType $filter),\n",
      "+   (IsInt32ElementType $conv),\n",
      "+   (HasStaticShapeConstraint $filter),\n",
      "+   (HasStaticShapeAtDimsConstraint<\"1, 2, 3\"> $input)],\n",
      "+  (addBenefit 10)>;\n",
      "\n",
      " ================================================================================ \n",
      "\n",
      "File name: utils.td\n",
      "File path: tensorflow/compiler/mlir/quantization/tensorflow/passes/utils.td\n",
      "Patch: \n",
      "@@ -50,6 +50,10 @@ def IsInt8ElementType : Constraint<\n",
      " def IsInt32ElementType : Constraint<\n",
      "   CPred<\"getElementTypeOrSelf($0).isInteger(32)\">>;\n",
      " \n",
      "+// Checks if the value has the type of float32.\n",
      "+def IsF32ElementType : Constraint<\n",
      "+  CPred<\"getElementTypeOrSelf($0).isF32()\">>;\n",
      "+\n",
      " // Checks if the value has static shape.\n",
      " def HasStaticShapeConstraint : Constraint<CPred<\"HasStaticShape($0)\">>;\n",
      " \n",
      "@@ -74,6 +78,15 @@ class Create1DConst<string values> : NativeCodeCall<\n",
      " class CreateScalarConst<string value> : NativeCodeCall<\n",
      "   \"CreateScalarConstValue<float>($_builder, $_loc, \"# value #\")\">;\n",
      " \n",
      "+// Creates an 1D array const with integer values.\n",
      "+// TODO(b/239490133): Make the rule name and function name consistent.\n",
      "+class Create1DIntegerConst<string type, string values> : NativeCodeCall<\n",
      "+  \"Create1DConstValue<\"# type #\">($_builder, $_loc, \"# values #\")\">;\n",
      "+\n",
      "+// Creates a scalar const with integer value.\n",
      "+class CreateScalarIntegerConst<string type, string value> : NativeCodeCall<\n",
      "+  \"CreateScalarConstValue<\"# type #\">($_builder, $_loc, \"# value #\")\">;\n",
      "+\n",
      " // Creates an I64 array attribute with given values.\n",
      " class CreateI64ArrayAttr<string values> : NativeCodeCall<\n",
      "   \"$_builder.getI64ArrayAttr(\"# values #\")\">;\n",
      "\n",
      " ================================================================================ \n",
      "\n",
      "File name: replace_cast_hacks_with_tf_xla_ops.mlir\n",
      "File path: tensorflow/compiler/mlir/quantization/tensorflow/tests/replace_cast_hacks_with_tf_xla_ops.mlir\n",
      "Patch: \n",
      "@@ -88,3 +88,87 @@ module attributes {tf.versions = {bad_consumers = [], min_consumer = 12 : i32, p\n",
      " }\n",
      " \n",
      " // -----\n",
      "+\n",
      "+module attributes {tf.versions = {bad_consumers = [], min_consumer = 12 : i32, producer = 1195 : i32}} {\n",
      "+  func.func @depthwise_conv_with_bias_and_relu6(%arg0: tensor<1x3x4x3xf32>) -> tensor<1x2x2x3xf32> {\n",
      "+    %cst = \"tf.Const\"() {value = dense<[129, 166, 221]> : tensor<3xi32>} : () -> tensor<3xi32>\n",
      "+    %cst_0 = \"tf.Const\"() {value = dense<[[[[-84], [73], [24]], [[-102], [-28], [-94]], [[-127], [-82], [82]]], [[[-56], [67], [120]], [[45], [11], [-88]], [[-106], [77], [123]]]]> : tensor<2x3x3x1xi8>} : () -> tensor<2x3x3x1xi8>\n",
      "+    %cst_1 = \"tf.Const\"() {value = dense<0.587548196> : tensor<f32>} : () -> tensor<f32>\n",
      "+    %cst_2 = \"tf.Const\"() {value = dense<-128> : tensor<i32>} : () -> tensor<i32>\n",
      "+    %cst_3 = \"tf.Const\"() {value = dense<0.0235294122> : tensor<f32>} : () -> tensor<f32>\n",
      "+    %cst_4 = \"tf.Const\"() {value = dense<0.0751230493> : tensor<1xf32>} : () -> tensor<1xf32>\n",
      "+    %cst_5 = \"tf.Const\"() {value = dense<0> : tensor<1xi32>} : () -> tensor<1xi32>\n",
      "+    %cst_6 = \"tf.Const\"() {value = dense<0.0441384129> : tensor<f32>} : () -> tensor<f32>\n",
      "+    %cst_7 = \"tf.Const\"() {value = dense<0> : tensor<i32>} : () -> tensor<i32>\n",
      "+    %0 = \"tf.PartitionedCall\"(%arg0, %cst_1, %cst_2) {config = \"\", config_proto = \"\", executor_type = \"\", f = @quantize_i8} : (tensor<1x3x4x3xf32>, tensor<f32>, tensor<i32>) -> tensor<1x3x4x3xi8>\n",
      "+    %1 = \"tf.PartitionedCall\"(%0, %cst_0, %cst, %cst_1, %cst_2, %cst_4, %cst_5, %cst_6, %cst_7, %cst_3, %cst_2) {config = \"\", config_proto = \"\", executor_type = \"\", f = @quantized_depthwise_conv2d_with_bias_and_relu6_fn_0} : (tensor<1x3x4x3xi8>, tensor<2x3x3x1xi8>, tensor<3xi32>, tensor<f32>, tensor<i32>, tensor<1xf32>, tensor<1xi32>, tensor<f32>, tensor<i32>, tensor<f32>, tensor<i32>) -> tensor<1x2x2x3xi8>\n",
      "+    %2 = \"tf.PartitionedCall\"(%1, %cst_3, %cst_2) {config = \"\", config_proto = \"\", executor_type = \"\", f = @dequantize_i8} : (tensor<1x2x2x3xi8>, tensor<f32>, tensor<i32>) -> tensor<1x2x2x3xf32>\n",
      "+    return %2 : tensor<1x2x2x3xf32>\n",
      "+  }\n",
      "+  func.func private @quantize_i8(%arg0: tensor<1x3x4x3xf32>, %arg1: tensor<f32>, %arg2: tensor<i32>) -> tensor<1x3x4x3xi8> {\n",
      "+    %0 = \"tf.Div\"(%arg0, %arg1) : (tensor<1x3x4x3xf32>, tensor<f32>) -> tensor<1x3x4x3xf32>\n",
      "+    %1 = \"tf.Round\"(%0) : (tensor<1x3x4x3xf32>) -> tensor<1x3x4x3xf32>\n",
      "+    %2 = \"tf.Cast\"(%1) : (tensor<1x3x4x3xf32>) -> tensor<1x3x4x3xi32>\n",
      "+    %3 = \"tf.AddV2\"(%2, %arg2) : (tensor<1x3x4x3xi32>, tensor<i32>) -> tensor<1x3x4x3xi32>\n",
      "+    %4 = \"tf.Cast\"(%3) {Truncate = false} : (tensor<1x3x4x3xi32>) -> tensor<1x3x4x3xi8>\n",
      "+    return %4 : tensor<1x3x4x3xi8>\n",
      "+  }\n",
      "+  func.func private @dequantize_i8(%arg0: tensor<1x2x2x3xi8>, %arg1: tensor<f32>, %arg2: tensor<i32>) -> tensor<1x2x2x3xf32> {\n",
      "+    %0 = \"tf.Cast\"(%arg0) : (tensor<1x2x2x3xi8>) -> tensor<1x2x2x3xi32>\n",
      "+    %1 = \"tf.Sub\"(%0, %arg2) : (tensor<1x2x2x3xi32>, tensor<i32>) -> tensor<1x2x2x3xi32>\n",
      "+    %2 = \"tf.Cast\"(%1) : (tensor<1x2x2x3xi32>) -> tensor<1x2x2x3xf32>\n",
      "+    %3 = \"tf.Mul\"(%2, %arg1) : (tensor<1x2x2x3xf32>, tensor<f32>) -> tensor<1x2x2x3xf32>\n",
      "+    return %3 : tensor<1x2x2x3xf32>\n",
      "+  }\n",
      "+  func.func private @quantized_depthwise_conv2d_with_bias_and_relu6_fn_0(%arg0: tensor<1x3x4x3xi8>, %arg1: tensor<2x3x3x1xi8>, %arg2: tensor<3xi32>, %arg3: tensor<f32>, %arg4: tensor<i32>, %arg5: tensor<1xf32>, %arg6: tensor<1xi32>, %arg7: tensor<f32>, %arg8: tensor<i32>, %arg9: tensor<f32>, %arg10: tensor<i32>) -> tensor<1x2x2x3xi8> {\n",
      "+    %cst = \"tf.Const\"() {value = dense<127> : tensor<i32>} : () -> tensor<i32>\n",
      "+    %cst_0 = \"tf.Const\"() {value = dense<-128> : tensor<i32>} : () -> tensor<i32>\n",
      "+    %cst_1 = \"tf.Const\"() {value = dense<6.000000e+00> : tensor<f32>} : () -> tensor<f32>\n",
      "+    %0 = \"tf.Cast\"(%arg0) {Truncate = false} : (tensor<1x3x4x3xi8>) -> tensor<1x3x4x3xi32>\n",
      "+    %1 = \"tf.Sub\"(%0, %arg4) : (tensor<1x3x4x3xi32>, tensor<i32>) -> tensor<1x3x4x3xi32>\n",
      "+    %2 = \"tf.Cast\"(%arg1) {Truncate = false} : (tensor<2x3x3x1xi8>) -> tensor<2x3x3x1xi32>\n",
      "+    %3 = \"tf.Sub\"(%2, %arg6) : (tensor<2x3x3x1xi32>, tensor<1xi32>) -> tensor<2x3x3x1xi32>\n",
      "+    %4 = \"tf.Identity\"(%3) : (tensor<2x3x3x1xi32>) -> tensor<2x3x3x1xi32>\n",
      "+    %5 = \"tf.Cast\"(%1) {Truncate = false} : (tensor<1x3x4x3xi32>) -> tensor<1x3x4x3xf32>\n",
      "+    %6 = \"tf.Cast\"(%4) {Truncate = false} : (tensor<2x3x3x1xi32>) -> tensor<2x3x3x1xf32>\n",
      "+    %7 = \"tf.DepthwiseConv2dNative\"(%5, %6) {dilations = [1, 1, 1, 1], explicit_paddings = [], padding = \"SAME\", strides = [1, 2, 2, 1]} : (tensor<1x3x4x3xf32>, tensor<2x3x3x1xf32>) -> tensor<1x2x2x3xf32>\n",
      "+    %8 = \"tf.Cast\"(%7) : (tensor<1x2x2x3xf32>) -> tensor<1x2x2x3xi32>\n",
      "+    %9 = \"tf.AddV2\"(%8, %arg2) : (tensor<1x2x2x3xi32>, tensor<3xi32>) -> tensor<1x2x2x3xi32>\n",
      "+    %10 = \"tf.Mul\"(%arg3, %arg5) : (tensor<f32>, tensor<1xf32>) -> tensor<1xf32>\n",
      "+    %11 = \"tf.Div\"(%10, %arg9) : (tensor<1xf32>, tensor<f32>) -> tensor<1xf32>\n",
      "+    %12 = \"tf.Cast\"(%9) {Truncate = false} : (tensor<1x2x2x3xi32>) -> tensor<1x2x2x3xf32>\n",
      "+    %13 = \"tf.Mul\"(%11, %12) : (tensor<1xf32>, tensor<1x2x2x3xf32>) -> tensor<1x2x2x3xf32>\n",
      "+    %14 = \"tf.Round\"(%13) : (tensor<1x2x2x3xf32>) -> tensor<1x2x2x3xf32>\n",
      "+    %15 = \"tf.Cast\"(%14) {Truncate = false} : (tensor<1x2x2x3xf32>) -> tensor<1x2x2x3xi32>\n",
      "+    %16 = \"tf.AddV2\"(%15, %arg10) : (tensor<1x2x2x3xi32>, tensor<i32>) -> tensor<1x2x2x3xi32>\n",
      "+    %17 = \"tf.Div\"(%cst_1, %arg9) : (tensor<f32>, tensor<f32>) -> tensor<f32>\n",
      "+    %18 = \"tf.Round\"(%17) : (tensor<f32>) -> tensor<f32>\n",
      "+    %19 = \"tf.Cast\"(%18) : (tensor<f32>) -> tensor<i32>\n",
      "+    %20 = \"tf.AddV2\"(%19, %arg10) : (tensor<i32>, tensor<i32>) -> tensor<i32>\n",
      "+    %21 = \"tf.Cast\"(%20) : (tensor<i32>) -> tensor<i8>\n",
      "+    %22 = \"tf.Cast\"(%21) {Truncate = false} : (tensor<i8>) -> tensor<i8>\n",
      "+    %23 = \"tf.Cast\"(%22) {Truncate = false} : (tensor<i8>) -> tensor<i32>\n",
      "+    %24 = \"tf.Maximum\"(%cst_0, %arg10) : (tensor<i32>, tensor<i32>) -> tensor<i32>\n",
      "+    %25 = \"tf.Minimum\"(%cst, %23) : (tensor<i32>, tensor<i32>) -> tensor<i32>\n",
      "+    %26 = \"tf.ClipByValue\"(%16, %24, %25) : (tensor<1x2x2x3xi32>, tensor<i32>, tensor<i32>) -> tensor<1x2x2x3xi32>\n",
      "+    %27 = \"tf.Cast\"(%26) {Truncate = false} : (tensor<1x2x2x3xi32>) -> tensor<1x2x2x3xi8>\n",
      "+    return %27 : tensor<1x2x2x3xi8>\n",
      "+  }\n",
      "+\n",
      "+// CHECK-LABEL: func @depthwise_conv_with_bias_and_relu6\n",
      "+// CHECK-DAG: %[[CONST_0:.*]] = \"tf.Const\"() {value = dense<{{.*}}> : tensor<4x2xi32>} : () -> tensor<4x2xi32>\n",
      "+// CHECK-DAG: %[[CONST_1:.*]] = \"tf.Const\"() {value = dense<-128> : tensor<i8>} : () -> tensor<i8>\n",
      "+// CHECK-DAG: %[[CONST_2:.*]] = \"tf.Const\"() {value = dense<{{.*}}> : tensor<2x3x1x3xi8>} : () -> tensor<2x3x1x3xi8>\n",
      "+// CHECK-DAG: %[[CONST_3:.*]] = \"tf.Const\"() {value = dense<2> : tensor<2xi32>} : () -> tensor<2xi32>\n",
      "+// CHECK-DAG: %[[CONST_4:.*]] = \"tf.Const\"() {value = dense<0> : tensor<2x2xi32>} : () -> tensor<2x2xi32>\n",
      "+// CHECK-DAG: %[[CONST_5:.*]] = \"tf.Const\"() {value = dense<1> : tensor<2xi32>} : () -> tensor<2xi32>\n",
      "+// CHECK-DAG: %[[CONST_6:.*]] = \"tf.Const\"() {value = dense<3> : tensor<i32>} : () -> tensor<i32>\n",
      "+// CHECK-DAG: %[[CONST_7:.*]] = \"tf.Const\"() {value = dense<[55040, -15104, -21376]> : tensor<3xi32>} : () -> tensor<3xi32>\n",
      "+// CHECK-DAG: %[[CONST_8:.*]] = \"tf.Const\"() {value = dense<[129, 166, 221]> : tensor<3xi32>} : () -> tensor<3xi32>\n",
      "+// CHECK: %[[PADV2_0:.*]] = \"tf.PadV2\"({{.*}}, %[[CONST_0]], %[[CONST_1]]) : (tensor<1x3x4x3xi8>, tensor<4x2xi32>, tensor<i8>) -> tensor<1x4x5x3xi8>\n",
      "+// CHECK: %[[XLACONVV2_0:.*]] = \"tf.XlaConvV2\"(%[[PADV2_0]], %[[CONST_2]], %[[CONST_3]], %[[CONST_4]], %[[CONST_5]], %[[CONST_5]], %[[CONST_6]])\n",
      "+// CHECK-SAME: (tensor<1x4x5x3xi8>, tensor<2x3x1x3xi8>, tensor<2xi32>, tensor<2x2xi32>, tensor<2xi32>, tensor<2xi32>, tensor<i32>) -> tensor<1x2x2x3xi32>\n",
      "+// CHECK: %[[SUB_0:.*]] = \"tf.Sub\"(%[[XLACONVV2_0]], %[[CONST_7]]) : (tensor<1x2x2x3xi32>, tensor<3xi32>) -> tensor<1x2x2x3xi32>\n",
      "+// CHECK: %[[ADDV2_1:.*]] = \"tf.AddV2\"(%[[SUB_0]], %[[CONST_8]]) : (tensor<1x2x2x3xi32>, tensor<3xi32>) -> tensor<1x2x2x3xi32>\n",
      "+}\n",
      "+\n",
      "\n",
      " ================================================================================ \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Iterate through the file and print the patch for each commit\n",
    "for index, row in file_df.iterrows():\n",
    "    print(f\"File name: {row.name}\")\n",
    "    print(f\"File path: {row['filename']}\")\n",
    "    print(f\"Patch: \")\n",
    "    print(row['patch'])\n",
    "    print(\"\\n\", \"=\"*80, \"\\n\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Parsed Patch"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File: passes-quantized_function_library.mlir\n",
      "__________________________________________________________________________________________ \n",
      "\n",
      "+ %identity = \"tf.Identity\"(%3) : (tensor<*xi32>) -> tensor<*xi32>\n",
      "__________________________________________________________________________________________ \n",
      "\n",
      "- %cast_3_f32 = \"tf.Cast\"(%3) {Truncate = false} : (tensor<*xi32>) -> tensor<*xf32>\n",
      "+ %cast_3_f32 = \"tf.Cast\"(%identity) {Truncate = false} : (tensor<*xi32>) -> tensor<*xf32>\n",
      "\n",
      " ========================================================================================== \n",
      "\n",
      "File: passes-replace_cast_hacks_with_tf_xla_ops.cc\n",
      "__________________________________________________________________________________________ \n",
      "\n",
      "- const int stride_h = strides[1].cast<mlir::IntegerAttr>().getInt();\n",
      "- const int stride_w = strides[2].cast<mlir::IntegerAttr>().getInt();\n",
      "+ const int stride_h = strides[1].cast<IntegerAttr>().getInt();\n",
      "+ const int stride_w = strides[2].cast<IntegerAttr>().getInt();\n",
      "__________________________________________________________________________________________ \n",
      "\n",
      "- const int dilation_h = dilations[1].cast<mlir::IntegerAttr>().getInt();\n",
      "- const int dilation_w = dilations[2].cast<mlir::IntegerAttr>().getInt();\n",
      "+ const int dilation_h = dilations[1].cast<IntegerAttr>().getInt();\n",
      "+ const int dilation_w = dilations[2].cast<IntegerAttr>().getInt();\n",
      "__________________________________________________________________________________________ \n",
      "\n",
      "- mlir::emitError(loc,\n",
      "- \"explicit_paddings are expected to be 8-element arrays\");\n",
      "+ emitError(loc, \"explicit_paddings are expected to be 8-element arrays\");\n",
      "__________________________________________________________________________________________ \n",
      "\n",
      "- padding_h_before = explicit_paddings[2].cast<mlir::IntegerAttr>().getInt();\n",
      "- padding_h_after = explicit_paddings[3].cast<mlir::IntegerAttr>().getInt();\n",
      "- padding_w_before = explicit_paddings[4].cast<mlir::IntegerAttr>().getInt();\n",
      "- padding_w_after = explicit_paddings[5].cast<mlir::IntegerAttr>().getInt();\n",
      "+ padding_h_before = explicit_paddings[2].cast<IntegerAttr>().getInt();\n",
      "+ padding_h_after = explicit_paddings[3].cast<IntegerAttr>().getInt();\n",
      "+ padding_w_before = explicit_paddings[4].cast<IntegerAttr>().getInt();\n",
      "+ padding_w_after = explicit_paddings[5].cast<IntegerAttr>().getInt();\n",
      "__________________________________________________________________________________________ \n",
      "\n",
      "- const int stride_h = strides[1].cast<mlir::IntegerAttr>().getInt();\n",
      "- const int stride_w = strides[2].cast<mlir::IntegerAttr>().getInt();\n",
      "- const int dilation_h = dilations[1].cast<mlir::IntegerAttr>().getInt();\n",
      "- const int dilation_w = dilations[2].cast<mlir::IntegerAttr>().getInt();\n",
      "+ const int stride_h = strides[1].cast<IntegerAttr>().getInt();\n",
      "+ const int stride_w = strides[2].cast<IntegerAttr>().getInt();\n",
      "+ const int dilation_h = dilations[1].cast<IntegerAttr>().getInt();\n",
      "+ const int dilation_w = dilations[2].cast<IntegerAttr>().getInt();\n",
      "__________________________________________________________________________________________ \n",
      "\n",
      "- Value CreateXLAConvOp(\n",
      "- OpBuilder &builder, Location loc, Value input, Value filter, Value input_zp,\n",
      "- Value conv_output, ArrayAttr strides, ArrayAttr dilations,\n",
      "- StringAttr conv_padding, ArrayAttr explicit_paddings, int feature_group_cnt,\n",
      "- const SmallVector<int64_t> &filter_non_output_indices,\n",
      "- const xla::ConvolutionDimensionNumbers &dimension_numbers) {\n",
      "+ Value CreateXLAConvOp(OpBuilder &builder, Location loc, Value input,\n",
      "+ Value filter, Value input_zp, Value conv_output,\n",
      "+ ArrayAttr strides, ArrayAttr dilations,\n",
      "+ StringAttr conv_padding, ArrayAttr explicit_paddings,\n",
      "+ int feature_group_cnt) {\n",
      "__________________________________________________________________________________________ \n",
      "\n",
      "- mlir::emitError(\n",
      "- loc, \"zero point is expected to be a constant with a single value\");\n",
      "+ emitError(loc,\n",
      "+ \"zero point is expected to be a constant with a single value\");\n",
      "__________________________________________________________________________________________ \n",
      "\n",
      "- mlir::emitError(\n",
      "- loc, \"strides and dilations are expected to be 4-element arrays\");\n",
      "+ emitError(loc, \"strides and dilations are expected to be 4-element arrays\");\n",
      "__________________________________________________________________________________________ \n",
      "\n",
      "- ShapedType input_shape = input.getType().template cast<ShapedType>();\n",
      "- if (!input_shape.hasRank() || input_shape.getRank() != 4 ||\n",
      "- !filter_shape.hasRank() || filter_shape.getRank() != 4) {\n",
      "- mlir::emitError(loc, \"input and filter are expected to be 4D tensors\");\n",
      "- return {};\n",
      "- }\n",
      "+ SmallVector<int64_t> filter_non_output_indices = {0, 1, 2};\n",
      "+ xla::ConvolutionDimensionNumbers dnums;\n",
      "+ dnums.set_input_batch_dimension(0);\n",
      "+ dnums.set_input_feature_dimension(3);\n",
      "+ dnums.add_input_spatial_dimensions(1);\n",
      "+ dnums.add_input_spatial_dimensions(2);\n",
      "+ dnums.set_kernel_input_feature_dimension(2);\n",
      "+ dnums.set_kernel_output_feature_dimension(3);\n",
      "+ dnums.add_kernel_spatial_dimensions(0);\n",
      "+ dnums.add_kernel_spatial_dimensions(1);\n",
      "+ dnums.set_output_batch_dimension(0);\n",
      "+ dnums.set_output_feature_dimension(3);\n",
      "+ dnums.add_output_spatial_dimensions(1);\n",
      "+ dnums.add_output_spatial_dimensions(2);\n",
      "__________________________________________________________________________________________ \n",
      "\n",
      "- auto filter_type = filter.getType().dyn_cast<TensorType>();\n",
      "+ TensorType filter_type = filter.getType().dyn_cast<TensorType>();\n",
      "__________________________________________________________________________________________ \n",
      "\n",
      "- loc, /*output=*/conv_output.getType(),\n",
      "+ loc, /*output_type=*/conv_output.getType(),\n",
      "__________________________________________________________________________________________ \n",
      "\n",
      "- builder.getStringAttr(dimension_numbers.SerializeAsString()),\n",
      "+ builder.getStringAttr(dnums.SerializeAsString()),\n",
      "__________________________________________________________________________________________ \n",
      "\n",
      "- const int feature_group_cnt = 1;\n",
      "- SmallVector<int64_t> filter_non_output_indices = {0, 1, 2};\n",
      "- xla::ConvolutionDimensionNumbers dnums;\n",
      "- dnums.set_input_batch_dimension(0);\n",
      "- dnums.set_input_feature_dimension(3);\n",
      "- dnums.add_input_spatial_dimensions(1);\n",
      "- dnums.add_input_spatial_dimensions(2);\n",
      "- dnums.set_kernel_input_feature_dimension(2);\n",
      "- dnums.set_kernel_output_feature_dimension(3);\n",
      "- dnums.add_kernel_spatial_dimensions(0);\n",
      "- dnums.add_kernel_spatial_dimensions(1);\n",
      "- dnums.set_output_batch_dimension(0);\n",
      "- dnums.set_output_feature_dimension(3);\n",
      "- dnums.add_output_spatial_dimensions(1);\n",
      "- dnums.add_output_spatial_dimensions(2);\n",
      "+ ShapedType input_shape = input.getType().template cast<ShapedType>();\n",
      "+ ShapedType filter_shape = filter.getType().template cast<ShapedType>();\n",
      "+ if (!input_shape.hasRank() || input_shape.getRank() != 4 ||\n",
      "+ !filter_shape.hasRank() || filter_shape.getRank() != 4) {\n",
      "+ emitError(loc, \"input and filter are expected to be 4D tensors\");\n",
      "+ return {};\n",
      "+ }\n",
      "+ const int feature_group_cnt =\n",
      "+ input_shape.getDimSize(3) / filter_shape.getDimSize(2);\n",
      "__________________________________________________________________________________________ \n",
      "\n",
      "- feature_group_cnt, filter_non_output_indices, dnums);\n",
      "+ feature_group_cnt);\n",
      "+ }\n",
      "+ Value CreateXLAConvOpFromTFDepthwiseConv2DOp(\n",
      "+ OpBuilder &builder, Location loc, Value input, Value filter, Value input_zp,\n",
      "+ Value conv_output, ArrayAttr strides, ArrayAttr dilations,\n",
      "+ StringAttr conv_padding, ArrayAttr explicit_paddings) {\n",
      "+ ShapedType input_shape = input.getType().template cast<ShapedType>();\n",
      "+ ShapedType filter_shape = filter.getType().template cast<ShapedType>();\n",
      "+ if (!input_shape.hasRank() || input_shape.getRank() != 4 ||\n",
      "+ !filter_shape.hasRank() || filter_shape.getRank() != 4) {\n",
      "+ emitError(loc, \"input and filter are expected to be 4D tensors\");\n",
      "+ return {};\n",
      "+ }\n",
      "+ const int feature_group_cnt = input_shape.getDimSize(3);\n",
      "+ llvm::SmallVector<int64_t> new_filter_shape{\n",
      "+ filter_shape.getDimSize(0), filter_shape.getDimSize(1), 1,\n",
      "+ filter_shape.getDimSize(2) * filter_shape.getDimSize(3)};\n",
      "+ Value new_filter = builder.create<TF::ReshapeOp>(\n",
      "+ loc,\n",
      "+ RankedTensorType::get(new_filter_shape, filter_shape.getElementType()),\n",
      "+ filter, Create1DConstValue(builder, loc, new_filter_shape));\n",
      "+ return CreateXLAConvOp(builder, loc, input, new_filter, input_zp, conv_output,\n",
      "+ strides, dilations, conv_padding, explicit_paddings,\n",
      "+ feature_group_cnt);\n",
      "\n",
      " ========================================================================================== \n",
      "\n",
      "File: passes-replace_cast_hacks_with_tf_xla_ops.td\n",
      "__________________________________________________________________________________________ \n",
      "\n",
      "+ def CreateXLAConvOpFromTFDepthwiseConv2DOp : NativeCodeCall<\n",
      "+ \"CreateXLAConvOpFromTFDepthwiseConv2DOp($_builder, $_loc, $0...)\">;\n",
      "__________________________________________________________________________________________ \n",
      "\n",
      "- (TF_SubOp (TF_CastOp $input, $truncate), $input_zp),\n",
      "- (TF_ConstOp:$filter $filter_value),\n",
      "- $strides, $use_cudnn, $padding, $explicit_padding,\n",
      "+ (TF_SubOp (TF_CastOp $input, $truncate), $input_zp),\n",
      "+ (TF_ConstOp:$filter $filter_value),\n",
      "+ $strides, $use_cudnn, $padding, $explicit_padding,\n",
      "+ def ConvertTFConv2DWithNoZeroPointToXLAConvOp : Pat<\n",
      "+ (TF_Conv2DOp:$conv\n",
      "+ (TF_CastOp $input, $truncate),\n",
      "+ (TF_ConstOp:$filter $filter_value),\n",
      "+ $strides, $use_cudnn, $padding, $explicit_padding,\n",
      "+ IsDataFormatNHWC:$data_format, $dilations),\n",
      "+ (CreateXLAConvOpFromTFConv2DOp\n",
      "+ $input, $filter, /*input_zp=*/(CreateScalarIntegerConst<\"int32_t\", \"0\">),\n",
      "+ $conv, $strides, $dilations, $padding, $explicit_padding),\n",
      "+ [(IsInt8ElementType $input),\n",
      "+ (IsInt32ElementType $filter),\n",
      "+ (IsInt32ElementType $conv),\n",
      "+ (HasStaticShapeConstraint $filter),\n",
      "+ (HasStaticShapeAtDimsConstraint<\"1, 2, 3\"> $input)],\n",
      "+ (addBenefit 10)>;\n",
      "+ def ConvertTFDepthwiseConv2DToXLAConvOp : Pat<\n",
      "+ (TF_CastOp:$conv\n",
      "+ (TF_DepthwiseConv2dNativeOp\n",
      "+ (TF_CastOp:$casted_input\n",
      "+ (TF_SubOp (TF_CastOp $input, $truncate1), $input_zp), $truncate2),\n",
      "+ (TF_CastOp\n",
      "+ (TF_IdentityOp (TF_ConstOp:$filter $filter_value)), $truncate3),\n",
      "+ $strides, $padding, $explicit_padding,\n",
      "+ IsDataFormatNHWC:$data_format, $dilations), $truncate4),\n",
      "+ (CreateXLAConvOpFromTFDepthwiseConv2DOp\n",
      "+ $input, $filter, $input_zp, $conv, $strides,\n",
      "+ $dilations, $padding, $explicit_padding),\n",
      "+ [(IsInt8ElementType $input),\n",
      "+ (IsF32ElementType $casted_input),\n",
      "+ (IsInt32ElementType $filter),\n",
      "+ (IsInt32ElementType $conv),\n",
      "+ (HasStaticShapeConstraint $filter),\n",
      "+ (HasStaticShapeAtDimsConstraint<\"1, 2, 3\"> $input)],\n",
      "+ (addBenefit 10)>;\n",
      "+ def ConvertTFDepthwiseConv2DWithNoZeroPointToXLAConvOp : Pat<\n",
      "+ (TF_CastOp:$conv\n",
      "+ (TF_DepthwiseConv2dNativeOp\n",
      "+ (TF_CastOp:$casted_input\n",
      "+ (TF_CastOp $input, $truncate1), $truncate2),\n",
      "+ (TF_CastOp\n",
      "+ (TF_IdentityOp (TF_ConstOp:$filter $filter_value)), $truncate3),\n",
      "+ $strides, $padding, $explicit_padding,\n",
      "+ IsDataFormatNHWC:$data_format, $dilations), $truncate4),\n",
      "+ (CreateXLAConvOpFromTFDepthwiseConv2DOp\n",
      "+ $input, $filter, /*input_zp=*/(CreateScalarIntegerConst<\"int32_t\", \"0\">),\n",
      "+ $conv, $strides, $dilations, $padding, $explicit_padding),\n",
      "+ [(IsInt8ElementType $input),\n",
      "+ (IsF32ElementType $casted_input),\n",
      "+ (IsInt32ElementType $filter),\n",
      "+ (IsInt32ElementType $conv),\n",
      "+ (HasStaticShapeConstraint $filter),\n",
      "+ (HasStaticShapeAtDimsConstraint<\"1, 2, 3\"> $input)],\n",
      "+ (addBenefit 10)>;\n",
      "\n",
      " ========================================================================================== \n",
      "\n",
      "File: passes-utils.td\n",
      "__________________________________________________________________________________________ \n",
      "\n",
      "+ def IsF32ElementType : Constraint<\n",
      "+ CPred<\"getElementTypeOrSelf($0).isF32()\">>;\n",
      "+ class Create1DIntegerConst<string type, string values> : NativeCodeCall<\n",
      "+ \"Create1DConstValue<\"# type #\">($_builder, $_loc, \"# values #\")\">;\n",
      "+ class CreateScalarIntegerConst<string type, string value> : NativeCodeCall<\n",
      "+ \"CreateScalarConstValue<\"# type #\">($_builder, $_loc, \"# value #\")\">;\n",
      "\n",
      " ========================================================================================== \n",
      "\n",
      "File: tests-replace_cast_hacks_with_tf_xla_ops.mlir\n",
      "__________________________________________________________________________________________ \n",
      "\n",
      "+ module attributes {tf.versions = {bad_consumers = [], min_consumer = 12 : i32, producer = 1195 : i32}} {\n",
      "+ func.func @depthwise_conv_with_bias_and_relu6(%arg0: tensor<1x3x4x3xf32>) -> tensor<1x2x2x3xf32> {\n",
      "+ %cst = \"tf.Const\"() {value = dense<[129, 166, 221]> : tensor<3xi32>} : () -> tensor<3xi32>\n",
      "+ %cst_0 = \"tf.Const\"() {value = dense<[[[[-84], [73], [24]], [[-102], [-28], [-94]], [[-127], [-82], [82]]], [[[-56], [67], [120]], [[45], [11], [-88]], [[-106], [77], [123]]]]> : tensor<2x3x3x1xi8>} : () -> tensor<2x3x3x1xi8>\n",
      "+ %cst_1 = \"tf.Const\"() {value = dense<0.587548196> : tensor<f32>} : () -> tensor<f32>\n",
      "+ %cst_2 = \"tf.Const\"() {value = dense<-128> : tensor<i32>} : () -> tensor<i32>\n",
      "+ %cst_3 = \"tf.Const\"() {value = dense<0.0235294122> : tensor<f32>} : () -> tensor<f32>\n",
      "+ %cst_4 = \"tf.Const\"() {value = dense<0.0751230493> : tensor<1xf32>} : () -> tensor<1xf32>\n",
      "+ %cst_5 = \"tf.Const\"() {value = dense<0> : tensor<1xi32>} : () -> tensor<1xi32>\n",
      "+ %cst_6 = \"tf.Const\"() {value = dense<0.0441384129> : tensor<f32>} : () -> tensor<f32>\n",
      "+ %cst_7 = \"tf.Const\"() {value = dense<0> : tensor<i32>} : () -> tensor<i32>\n",
      "+ %0 = \"tf.PartitionedCall\"(%arg0, %cst_1, %cst_2) {config = \"\", config_proto = \"\", executor_type = \"\", f = @quantize_i8} : (tensor<1x3x4x3xf32>, tensor<f32>, tensor<i32>) -> tensor<1x3x4x3xi8>\n",
      "+ %1 = \"tf.PartitionedCall\"(%0, %cst_0, %cst, %cst_1, %cst_2, %cst_4, %cst_5, %cst_6, %cst_7, %cst_3, %cst_2) {config = \"\", config_proto = \"\", executor_type = \"\", f = @quantized_depthwise_conv2d_with_bias_and_relu6_fn_0} : (tensor<1x3x4x3xi8>, tensor<2x3x3x1xi8>, tensor<3xi32>, tensor<f32>, tensor<i32>, tensor<1xf32>, tensor<1xi32>, tensor<f32>, tensor<i32>, tensor<f32>, tensor<i32>) -> tensor<1x2x2x3xi8>\n",
      "+ %2 = \"tf.PartitionedCall\"(%1, %cst_3, %cst_2) {config = \"\", config_proto = \"\", executor_type = \"\", f = @dequantize_i8} : (tensor<1x2x2x3xi8>, tensor<f32>, tensor<i32>) -> tensor<1x2x2x3xf32>\n",
      "+ return %2 : tensor<1x2x2x3xf32>\n",
      "+ }\n",
      "+ func.func private @quantize_i8(%arg0: tensor<1x3x4x3xf32>, %arg1: tensor<f32>, %arg2: tensor<i32>) -> tensor<1x3x4x3xi8> {\n",
      "+ %0 = \"tf.Div\"(%arg0, %arg1) : (tensor<1x3x4x3xf32>, tensor<f32>) -> tensor<1x3x4x3xf32>\n",
      "+ %1 = \"tf.Round\"(%0) : (tensor<1x3x4x3xf32>) -> tensor<1x3x4x3xf32>\n",
      "+ %2 = \"tf.Cast\"(%1) : (tensor<1x3x4x3xf32>) -> tensor<1x3x4x3xi32>\n",
      "+ %3 = \"tf.AddV2\"(%2, %arg2) : (tensor<1x3x4x3xi32>, tensor<i32>) -> tensor<1x3x4x3xi32>\n",
      "+ %4 = \"tf.Cast\"(%3) {Truncate = false} : (tensor<1x3x4x3xi32>) -> tensor<1x3x4x3xi8>\n",
      "+ return %4 : tensor<1x3x4x3xi8>\n",
      "+ }\n",
      "+ func.func private @dequantize_i8(%arg0: tensor<1x2x2x3xi8>, %arg1: tensor<f32>, %arg2: tensor<i32>) -> tensor<1x2x2x3xf32> {\n",
      "+ %0 = \"tf.Cast\"(%arg0) : (tensor<1x2x2x3xi8>) -> tensor<1x2x2x3xi32>\n",
      "+ %1 = \"tf.Sub\"(%0, %arg2) : (tensor<1x2x2x3xi32>, tensor<i32>) -> tensor<1x2x2x3xi32>\n",
      "+ %2 = \"tf.Cast\"(%1) : (tensor<1x2x2x3xi32>) -> tensor<1x2x2x3xf32>\n",
      "+ %3 = \"tf.Mul\"(%2, %arg1) : (tensor<1x2x2x3xf32>, tensor<f32>) -> tensor<1x2x2x3xf32>\n",
      "+ return %3 : tensor<1x2x2x3xf32>\n",
      "+ }\n",
      "+ func.func private @quantized_depthwise_conv2d_with_bias_and_relu6_fn_0(%arg0: tensor<1x3x4x3xi8>, %arg1: tensor<2x3x3x1xi8>, %arg2: tensor<3xi32>, %arg3: tensor<f32>, %arg4: tensor<i32>, %arg5: tensor<1xf32>, %arg6: tensor<1xi32>, %arg7: tensor<f32>, %arg8: tensor<i32>, %arg9: tensor<f32>, %arg10: tensor<i32>) -> tensor<1x2x2x3xi8> {\n",
      "+ %cst = \"tf.Const\"() {value = dense<127> : tensor<i32>} : () -> tensor<i32>\n",
      "+ %cst_0 = \"tf.Const\"() {value = dense<-128> : tensor<i32>} : () -> tensor<i32>\n",
      "+ %cst_1 = \"tf.Const\"() {value = dense<6.000000e+00> : tensor<f32>} : () -> tensor<f32>\n",
      "+ %0 = \"tf.Cast\"(%arg0) {Truncate = false} : (tensor<1x3x4x3xi8>) -> tensor<1x3x4x3xi32>\n",
      "+ %1 = \"tf.Sub\"(%0, %arg4) : (tensor<1x3x4x3xi32>, tensor<i32>) -> tensor<1x3x4x3xi32>\n",
      "+ %2 = \"tf.Cast\"(%arg1) {Truncate = false} : (tensor<2x3x3x1xi8>) -> tensor<2x3x3x1xi32>\n",
      "+ %3 = \"tf.Sub\"(%2, %arg6) : (tensor<2x3x3x1xi32>, tensor<1xi32>) -> tensor<2x3x3x1xi32>\n",
      "+ %4 = \"tf.Identity\"(%3) : (tensor<2x3x3x1xi32>) -> tensor<2x3x3x1xi32>\n",
      "+ %5 = \"tf.Cast\"(%1) {Truncate = false} : (tensor<1x3x4x3xi32>) -> tensor<1x3x4x3xf32>\n",
      "+ %6 = \"tf.Cast\"(%4) {Truncate = false} : (tensor<2x3x3x1xi32>) -> tensor<2x3x3x1xf32>\n",
      "+ %7 = \"tf.DepthwiseConv2dNative\"(%5, %6) {dilations = [1, 1, 1, 1], explicit_paddings = [], padding = \"SAME\", strides = [1, 2, 2, 1]} : (tensor<1x3x4x3xf32>, tensor<2x3x3x1xf32>) -> tensor<1x2x2x3xf32>\n",
      "+ %8 = \"tf.Cast\"(%7) : (tensor<1x2x2x3xf32>) -> tensor<1x2x2x3xi32>\n",
      "+ %9 = \"tf.AddV2\"(%8, %arg2) : (tensor<1x2x2x3xi32>, tensor<3xi32>) -> tensor<1x2x2x3xi32>\n",
      "+ %10 = \"tf.Mul\"(%arg3, %arg5) : (tensor<f32>, tensor<1xf32>) -> tensor<1xf32>\n",
      "+ %11 = \"tf.Div\"(%10, %arg9) : (tensor<1xf32>, tensor<f32>) -> tensor<1xf32>\n",
      "+ %12 = \"tf.Cast\"(%9) {Truncate = false} : (tensor<1x2x2x3xi32>) -> tensor<1x2x2x3xf32>\n",
      "+ %13 = \"tf.Mul\"(%11, %12) : (tensor<1xf32>, tensor<1x2x2x3xf32>) -> tensor<1x2x2x3xf32>\n",
      "+ %14 = \"tf.Round\"(%13) : (tensor<1x2x2x3xf32>) -> tensor<1x2x2x3xf32>\n",
      "+ %15 = \"tf.Cast\"(%14) {Truncate = false} : (tensor<1x2x2x3xf32>) -> tensor<1x2x2x3xi32>\n",
      "+ %16 = \"tf.AddV2\"(%15, %arg10) : (tensor<1x2x2x3xi32>, tensor<i32>) -> tensor<1x2x2x3xi32>\n",
      "+ %17 = \"tf.Div\"(%cst_1, %arg9) : (tensor<f32>, tensor<f32>) -> tensor<f32>\n",
      "+ %18 = \"tf.Round\"(%17) : (tensor<f32>) -> tensor<f32>\n",
      "+ %19 = \"tf.Cast\"(%18) : (tensor<f32>) -> tensor<i32>\n",
      "+ %20 = \"tf.AddV2\"(%19, %arg10) : (tensor<i32>, tensor<i32>) -> tensor<i32>\n",
      "+ %21 = \"tf.Cast\"(%20) : (tensor<i32>) -> tensor<i8>\n",
      "+ %22 = \"tf.Cast\"(%21) {Truncate = false} : (tensor<i8>) -> tensor<i8>\n",
      "+ %23 = \"tf.Cast\"(%22) {Truncate = false} : (tensor<i8>) -> tensor<i32>\n",
      "+ %24 = \"tf.Maximum\"(%cst_0, %arg10) : (tensor<i32>, tensor<i32>) -> tensor<i32>\n",
      "+ %25 = \"tf.Minimum\"(%cst, %23) : (tensor<i32>, tensor<i32>) -> tensor<i32>\n",
      "+ %26 = \"tf.ClipByValue\"(%16, %24, %25) : (tensor<1x2x2x3xi32>, tensor<i32>, tensor<i32>) -> tensor<1x2x2x3xi32>\n",
      "+ %27 = \"tf.Cast\"(%26) {Truncate = false} : (tensor<1x2x2x3xi32>) -> tensor<1x2x2x3xi8>\n",
      "+ return %27 : tensor<1x2x2x3xi8>\n",
      "+ }\n",
      "+ }\n",
      "\n",
      " ========================================================================================== \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Save parsed files\n",
    "parsed_files = {}\n",
    "\n",
    "# Iterate through each file and parse patch\n",
    "for index, row in file_df.iterrows():\n",
    "    # Parse file\n",
    "    parsed_patch = parse_patch(row['patch'])\n",
    "\n",
    "    # Cache File\n",
    "    fn_split = row.filename.split(\"/\")\n",
    "    _file_name = fn_split[-1] if len(fn_split) <= 1 else \"-\".join(fn_split[-2:])\n",
    "    parsed_files[_file_name] = parsed_patch\n",
    "\n",
    "    # Print File Name\n",
    "    print(f\"File: {_file_name}\")\n",
    "\n",
    "    # Print parsed patch\n",
    "    for _set in parsed_patch:\n",
    "        print(\"_\"*90, \"\\n\")\n",
    "\n",
    "        _dels = _set[0]\n",
    "        _adds = _set[1]\n",
    "\n",
    "        for _line in _dels:\n",
    "            print(f\"- {_line}\")\n",
    "        for _line in _adds:\n",
    "            print(f\"+ {_line}\")\n",
    "\n",
    "    print(\"\\n\", \"=\"*90, \"\\n\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Basic Checks"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File: passes-quantized_function_library.mlir\n",
      "# Additions: 2\n",
      "# Deletions: 1\n",
      "Net Change: 1\n",
      "\n",
      " ================================================================================ \n",
      "\n",
      "File: passes-replace_cast_hacks_with_tf_xla_ops.cc\n",
      "# Additions: 71\n",
      "# Deletions: 49\n",
      "Net Change: 22\n",
      "\n",
      " ================================================================================ \n",
      "\n",
      "File: passes-replace_cast_hacks_with_tf_xla_ops.td\n",
      "# Additions: 58\n",
      "# Deletions: 3\n",
      "Net Change: 55\n",
      "\n",
      " ================================================================================ \n",
      "\n",
      "File: passes-utils.td\n",
      "# Additions: 6\n",
      "# Deletions: 0\n",
      "Net Change: 6\n",
      "\n",
      " ================================================================================ \n",
      "\n",
      "File: tests-replace_cast_hacks_with_tf_xla_ops.mlir\n",
      "# Additions: 66\n",
      "# Deletions: 0\n",
      "Net Change: 66\n",
      "\n",
      " ================================================================================ \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Iterate through parsed files and compare len of additions and deletions\n",
    "for _file_name, _parsed_patch in parsed_files.items():\n",
    "    # Get len of additions and deletions\n",
    "    _adds = [len(x[1]) for x in _parsed_patch]\n",
    "    _dels = [len(x[0]) for x in _parsed_patch]\n",
    "\n",
    "    # Print stats\n",
    "    print(f\"File: {_file_name}\")\n",
    "    print(f\"# Additions: {sum(_adds)}\")\n",
    "    print(f\"# Deletions: {sum(_dels)}\")\n",
    "    print(f\"Net Change: {sum(_adds) - sum(_dels)}\")\n",
    "    print(\"\\n\", \"=\"*80, \"\\n\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}